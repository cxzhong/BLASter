name: Documentation and Examples

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'docs/**'
      - 'examples/**'
      - '*.md'
      - 'src/blaster/**/*.py'
  pull_request:
    branches: [ main ]
    paths:
      - 'docs/**'
      - 'examples/**'
      - '*.md'
      - 'src/blaster/**/*.py'
  workflow_dispatch:

jobs:
  validate-examples:
    name: Validate Example Scripts
    runs-on: ${{ matrix.os }}
    
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.11', '3.12', '3.13']
        exclude:
          - os: macos-latest
            python-version: '3.11'
          - os: windows-latest
            python-version: '3.12'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install BLASter from source
      run: |
        python -m pip install --upgrade pip
        pip install -e .
    
    - name: Validate demo.py
      run: |
        echo "[TEST] Testing examples/demo.py"
        python examples/demo.py
        echo "[OK] Demo script executed successfully"
    
    - name: Validate README examples
      run: |
        echo "[DOCS] Testing README code examples"
        python -c "
        # Test the basic example from README
        import blaster
        import numpy as np
        
        # Example 1: Basic LLL reduction
        basis = np.array([[10, 2, 3], [1, 12, 4], [2, 1, 15]])
        result = blaster.lll_reduce(basis)
        print(f'[OK] Basic LLL example: RHF = {result.rhf:.6f}')
        
        # Example 2: BKZ reduction
        bkz_result = blaster.bkz_reduce(basis, beta=5)
        print(f'[OK] BKZ example: RHF = {bkz_result.rhf:.6f}')
        
        # Example 3: Convenience function
        reduced = blaster.lll(basis)
        print(f'[OK] Convenience function: shape = {reduced.shape}')
        
        print('SUCCESS: All README examples work!')
        "
    
    - name: Test interface examples
      run: |
        echo "ðŸ”§ Testing interface examples from INTERFACE_README.md"
        python -c "
        import blaster
        import numpy as np
        
        # Test comprehensive interface examples
        basis = np.array([[15, 3, 2], [2, 14, 1], [1, 2, 16]])
        
        # Test with different parameters
        result1 = blaster.lll_reduce(basis, delta=0.99, verbose=False)
        result2 = blaster.lll_reduce(basis, delta=0.95, verbose=False)
        result3 = blaster.bkz_reduce(basis, beta=10, verbose=False)
        
        print(f'[OK] Interface test 1: RHF = {result1.rhf:.6f}')
        print(f'[OK] Interface test 2: RHF = {result2.rhf:.6f}') 
        print(f'[OK] Interface test 3: RHF = {result3.rhf:.6f}')
        
        # Test quality metrics
        print(f'[OK] Quality metrics available: {hasattr(result1, \"orthogonality_defect\")}')
        
        print('SUCCESS: All interface examples work!')
        "

  check-documentation:
    name: Documentation Completeness Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Check documentation structure
      run: |
        echo "[CHECK] Checking documentation completeness..."
        
        # Check essential files exist
        echo "Checking essential documentation files:"
        files_to_check=(
          "README.md"
          "INTERFACE_README.md" 
          "examples/demo.py"
          "LICENSE"
          "pyproject.toml"
        )
        
        for file in "${files_to_check[@]}"; do
          if [ -f "$file" ]; then
            echo "[OK] $file exists"
          else
            echo "[ERROR] Missing: $file"
            exit 1
          fi
        done
        
        echo "[OK] All essential files present"
    
    - name: Check README content
      run: |
        echo "[README] Checking README.md content..."
        
        # Check that README contains essential sections
        sections=(
          "installation"
          "usage" 
          "example"
          "BLASter"
          "lattice"
          "LLL"
        )
        
        for section in "${sections[@]}"; do
          if grep -qi "$section" README.md; then
            echo "[OK] README mentions: $section"
          else
            echo "[WARNING] README might be missing content about: $section"
          fi
        done
        
        # Check for modern installation instructions
        if grep -q "pip install" README.md; then
          echo "[OK] README includes pip installation"
        else
          echo "[ERROR] README missing pip installation instructions"
          exit 1
        fi
        
        if grep -q "automatic" README.md || grep -q "Eigen" README.md; then
          echo "[OK] README mentions automatic dependency management"
        else
          echo "[WARNING] README should mention automatic Eigen3 management"
        fi
    
    - name: Check interface documentation
      run: |
        echo "ðŸ”Œ Checking INTERFACE_README.md content..."
        
        # Check interface documentation completeness
        interface_sections=(
          "LLLResult"
          "lll_reduce"
          "bkz_reduce"
          "numpy"
          "example"
        )
        
        for section in "${interface_sections[@]}"; do
          if grep -qi "$section" INTERFACE_README.md; then
            echo "[OK] Interface docs mention: $section"
          else
            echo "[WARNING] Interface docs might be missing: $section"
          fi
        done
    
    - name: Validate code blocks in documentation
      run: |
        echo "[CODE] Checking code block syntax in documentation..."
        
        # Extract and validate Python code blocks from README
        python3 << 'EOF'
        import re
        import ast
        
        def check_python_code_blocks(filename):
            print(f"Checking Python code blocks in {filename}")
            
            with open(filename, 'r') as f:
                content = f.read()
            
            # Find Python code blocks
            pattern = r'```python\n(.*?)\n```'
            code_blocks = re.findall(pattern, content, re.DOTALL)
            
            for i, block in enumerate(code_blocks):
                try:
                    # Try to parse the code block
                    ast.parse(block)
                    print(f"[OK] Code block {i+1} syntax is valid")
                except SyntaxError as e:
                    print(f"[ERROR] Code block {i+1} has syntax error: {e}")
                    print(f"Block content:\n{block}")
                    return False
            
            return True
        
        # Check both README files
        success = True
        success &= check_python_code_blocks("README.md")
        success &= check_python_code_blocks("INTERFACE_README.md") 
        
        if success:
            print("[OK] All Python code blocks are syntactically valid")
        else:
            print("[ERROR] Some code blocks have syntax errors")
            exit(1)
        EOF

  benchmark-examples:
    name: Performance Benchmark Examples
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install BLASter with benchmarking tools
      run: |
        python -m pip install --upgrade pip
        pip install -e .
        pip install matplotlib seaborn pandas  # For potential plotting
    
    - name: Run comprehensive examples
      run: |
        echo "[RUNNING] Running comprehensive examples and benchmarks..."
        python -c "
        import blaster
        import numpy as np
        import time
        
        print('[ANALYSIS] BLASter Comprehensive Test Suite')
        print('=' * 50)
        
        # Test 1: Small dimension lattices
        print('\\n[INFO] Test 1: Small Dimension Lattices')
        dimensions = [4, 6, 8, 10]
        for dim in dimensions:
            basis = np.random.randint(-10, 11, size=(dim, dim))
            
            start_time = time.time()
            result = blaster.lll_reduce(basis, verbose=False)
            elapsed = time.time() - start_time
            
            print(f'{dim}x{dim}: {elapsed:.3f}s, RHF={result.rhf:.6f}, Ortho={result.orthogonality_defect:.3f}')
        
        # Test 2: Different algorithms
        print('\\nðŸ”§ Test 2: Algorithm Comparison') 
        test_basis = np.random.randint(-5, 6, size=(12, 12))
        
        lll_result = blaster.lll_reduce(test_basis, verbose=False)
        bkz_result = blaster.bkz_reduce(test_basis, beta=10, verbose=False)
        
        print(f'LLL: RHF={lll_result.rhf:.6f}')
        print(f'BKZ-10: RHF={bkz_result.rhf:.6f}')
        
        # Test 3: Quality verification
        print('\\n[OK] Test 3: Quality Verification')
        test_result = blaster.lll_reduce(np.array([[1, 2], [2, 5]]), verbose=False)
        verification = test_result.verify_transformation()
        print(f'Transformation verification: {verification}')
        
        # Test 4: Edge cases
        print('\\n[STATUS] Test 4: Edge Cases')
        
        # Identity matrix
        identity = np.eye(5, dtype=int)
        id_result = blaster.lll_reduce(identity, verbose=False)
        print(f'Identity matrix RHF: {id_result.rhf:.6f}')
        
        # Already reduced basis
        reduced_basis = np.array([[1, 0], [0, 1]])
        reduced_result = blaster.lll_reduce(reduced_basis, verbose=False)
        print(f'Already reduced RHF: {reduced_result.rhf:.6f}')
        
        print('\\nSUCCESS: All comprehensive tests completed successfully!')
        "
    
    - name: Test console script functionality  
      run: |
        echo "[SCRIPT] Testing console script functionality..."
        
        # Test help command
        blaster --help
        
        # Create a test input file
        python -c "
        import numpy as np
        np.savetxt('test_basis.txt', np.array([[10, 1], [1, 10]]), fmt='%d')
        "
        
        # Test console script with file (if supported)
        echo "[OK] Console script help works"
    
    - name: Generate example performance report
      run: |
        echo "[BENCHMARK] Generating performance characteristics report..."
        python -c "
        import blaster
        import numpy as np
        import time
        
        print('# BLASter Performance Characteristics')
        print()
        print('| Dimension | Time (s) | RHF | Memory Usage |')
        print('|-----------|----------|-----|--------------|')
        
        for dim in [6, 8, 10, 12, 16]:
            # Generate test basis
            basis = np.random.randint(-10, 11, size=(dim, dim))
            
            # Measure performance
            start_time = time.time()
            start_mem = 0  # Basic timing only
            
            result = blaster.lll_reduce(basis, verbose=False)
            
            elapsed = time.time() - start_time
            
            print(f'| {dim}x{dim} | {elapsed:.3f} | {result.rhf:.4f} | ~{dim*dim*8}B |')
        
        print()
        print('Performance measured on GitHub Actions runner')
        " > performance-report.md
        
        cat performance-report.md
    
    - name: Upload performance report
      uses: actions/upload-artifact@v4
      with:
        name: performance-report
        path: performance-report.md
        retention-days: 7

  check-links:
    name: Check Documentation Links
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Install link checker
      run: |
        npm install -g markdown-link-check
    
    - name: Check links in README.md
      run: |
        echo "[LINKS] Checking links in README.md..."
        markdown-link-check README.md || echo "Some links might be broken (non-blocking)"
    
    - name: Check links in INTERFACE_README.md
      run: |
        echo "[LINKS] Checking links in INTERFACE_README.md..."
        markdown-link-check INTERFACE_README.md || echo "Some links might be broken (non-blocking)"

  documentation-summary:
    name: Documentation Summary
    needs: [validate-examples, check-documentation, benchmark-examples]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
    - name: Generate documentation status report
      run: |
        echo "# [DOCS] Documentation Status Report" > doc-summary.md
        echo "Generated: $(date)" >> doc-summary.md
        echo "" >> doc-summary.md
        
        echo "## [TEST] Example Validation" >> doc-summary.md
        echo "Status: ${{ needs.validate-examples.result }}" >> doc-summary.md
        echo "" >> doc-summary.md
        
        echo "## [CHECK] Documentation Completeness" >> doc-summary.md
        echo "Status: ${{ needs.check-documentation.result }}" >> doc-summary.md
        echo "" >> doc-summary.md
        
        echo "## [RUNNING] Performance Benchmarks" >> doc-summary.md  
        echo "Status: ${{ needs.benchmark-examples.result }}" >> doc-summary.md
        echo "" >> doc-summary.md
        
        echo "## [OK] Overall Assessment" >> doc-summary.md
        if [[ "${{ needs.validate-examples.result }}" == "success" && "${{ needs.check-documentation.result }}" == "success" ]]; then
          echo "All documentation checks passed! SUCCESS:" >> doc-summary.md
        else
          echo "Some documentation checks need attention. [WARNING]" >> doc-summary.md
        fi
        
        cat doc-summary.md
    
    - name: Upload documentation summary
      uses: actions/upload-artifact@v4
      with:
        name: documentation-summary
        path: doc-summary.md
        retention-days: 30